{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a430a6",
   "metadata": {},
   "source": [
    "# Available Function \n",
    "This document summarizes the available functions present in the SDK\n",
    "\n",
    "---\n",
    "## 1. Create UDP client (Unstructured Data Processor)\n",
    "\n",
    "\n",
    "The `udp` Python SDK is designed to streamline interactions with the Unstructured Data Processing (UDP) service on Cloud Pak for Data (CP4D). It provides a high-level interface to effortlessly create, manage, and execute data flows. At the heart of the SDK is the `UDPClient` class, which enables developers to define and run UDP flows with minimal code, making it easier to integrate unstructured data processing capabilities into Python-based workflows.\n",
    "\n",
    "### Configuration for UDPClient\n",
    "To initialize the UDPClient, you need to provide a configuration dictionary with the following keys:\n",
    "* ### Example\n",
    "    ```python\n",
    "                {\n",
    "                'base_url': \"<URL of the UDP service>\",  # e.g., \"https://dummy.com/\"\n",
    "                'token': None,                           # Optional: Use if you have a bearer token\n",
    "                'project_id': \"420f8ed1589d48c\",         # Required: Your project identifier\n",
    "                'user_name': \"\",                         # Optional: Used if token is not provided\n",
    "                'password': \"\",                          # Optional: Used with user_name\n",
    "                'api_key': \"\",                           # Optional: Alternative to token or username/password\n",
    "                'env': 'cpd'                             # Required: Environment type\n",
    "            }\n",
    "For CPD environments, the base URL should be in the format:\n",
    "https://cpd-wkc.apps.udptest7.cp.fyre.ibm.comm\n",
    "\n",
    "For Cloud environments, the base URL should be in the format:\n",
    "https://api.dai.dev.cloud.ibm.com/           \n",
    "\n",
    "### Authentication Options\n",
    "You must provide one of the following authentication methods:\n",
    "\n",
    "* token\n",
    "* user_name and password\n",
    "* api_key\n",
    "‚ö†Ô∏è If more than one method is provided, the client will prioritize them in the order: token ‚Üí api_key ‚Üí user_name/password.\n",
    "\n",
    "### Environment (env)\n",
    "The env key specifies the environment in which the client will operate. Valid values include:\n",
    "\n",
    "* \"cpd\" ‚Äì Cloud Pak for Data\n",
    "* \"cloud-dev\" ‚Äì Development environment\n",
    "* \"cloud-test\" ‚Äì Testing environment\n",
    "* \"cloud-prod\" ‚Äì Production environment\n",
    "\n",
    "## 2.Get metadata\n",
    "From this all operator names and their attributes, features and required values can be retrieved.\n",
    "* Example\n",
    "    `metadata = uc.get_metadata()`\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4267c",
   "metadata": {},
   "source": [
    "# 3.Available Operators \n",
    "This summarizes the available operators grouped by their functional categories.\n",
    "\n",
    "---\n",
    "Each operator is defined by both an attribute schema and a feature schema, which together describe how the operator functions and how its data can be processed and filtered.\n",
    "\n",
    "üß© Attributes: <br>\n",
    "Each Operator has its own specific attribute and parameters.<br>\n",
    "Each attribute usually includes:\n",
    "\n",
    "        name: This is the display name shown in user interfaces or documentation.\n",
    "        description: This explains the purpose of the attribute.\n",
    "        Default: This is the default value used if the user does not provide one.\n",
    "        Required: This indicates whether the attribute is mandatory.\n",
    "        valid_values: This indicates allowed options for a particular attribute.\n",
    "\n",
    "üß© Features:<br>\n",
    "Each Operator has it own features that it adds to the table. These features can be used with sql_filter operator to run Queries. Retrieve the list of features added by each operator.<br>\n",
    "Each Features usually includes:\n",
    "\n",
    "        name: This is the display name of the feature, shown in interfaces or documentation.\n",
    "        description: Explains that this field contains a unique identifier for each document.\n",
    "        available_for_filter: Indicates that this feature can be used to filter documents (e.g., search by ID).\n",
    "        available_for_vector_db: This feature is required when storing the document in a vector database.\n",
    "        type: The data type of the feature<br>\n",
    "        \n",
    "<div style=\"\n",
    "    border-left: 6px solid #fbc02d;\n",
    "    background-color: #fff8e1;\n",
    "    padding: 12px 16px;\n",
    "    border-radius: 6px;\n",
    "    font-family: sans-serif;\n",
    "\">\n",
    "\n",
    "üí° <b style=\"color:#f57f17;\">Tip:</b>  \n",
    "You can use the <code>get_attributes()</code> and <code>get_features()</code> functions to inspect what settings (attributes) and data properties (features) are available for any operator.\n",
    "\n",
    "<div style=\"\n",
    "    background: #fff3cd;\n",
    "    padding: 10px;\n",
    "    border-radius: 4px;\n",
    "    font-family: monospace;\n",
    "    font-size: 90%;\n",
    "    line-height: 1.4;\n",
    "    margin-top: 10px;\n",
    "    white-space: pre;\n",
    "\">\n",
    "operator_attributes = get_attributes(metadata, \"extract_cpd\")\n",
    "operator_features   = get_features(metadata, \"extract_cpd\")\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "## Ingest Operator\n",
    "This operator is used to bring data into the system from various sources.\n",
    "* ### `ingest_cpd_assets`\n",
    "    The ingest_cpd_assets operator is used to ingest assets of type data_asset in the project. It allows users to specify which assets to ingest, apply filters based on file type, and skip files that exceed a certain size.\n",
    "    *  ####  Example for get_attribute\n",
    "        `operator_attributes = get_attributes(metadata, \"ingest_cpd_assets\") `<br>\n",
    "       ` print(json.dumps(operator_attributes, indent=2))`\n",
    "        ```json\n",
    "        {\n",
    "            \"max_file_size\": {\n",
    "                \"name\": \"Max File Size\",\n",
    "                \"description\": \"If the document is larger than the given max file size, then it will be skipped\",\n",
    "                \"default\": 100,\n",
    "                \"required\": true\n",
    "            },\n",
    "            \"cp4d_asset_ids\": {\n",
    "                \"name\": \"Asset ID's\",\n",
    "                \"description\": \"IDs of the assets to be ingested\",\n",
    "                \"default\": null,\n",
    "                \"required\": true\n",
    "            },\n",
    "            \"include_filter\": {\n",
    "                \"name\": \"Include File Type\",\n",
    "                \"description\": \"File types to be included\",\n",
    "                \"default\": \"pdf,txt,md\",\n",
    "                \"required\": false\n",
    "            }\n",
    "        }\n",
    "    *  ####  Example for get_feature\n",
    "\n",
    "       ` operator_feature = get_features(metadata, \"ingest_cpd_assets\")`<br>\n",
    "       ` print(json.dumps(operator_attributes, indent=2))`\n",
    "        \n",
    "        ```json \n",
    "        {\n",
    "            \"id\": {\n",
    "                \"name\": \"ID\",\n",
    "                \"description\": \"The ID of the document\",\n",
    "                \"available_for_filter\": true,\n",
    "                \"available_for_vector_db\": true,\n",
    "                \"mandatory_for_vector_db\": true,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"name\": \"Document Name\",\n",
    "                \"description\": \"The name of the document\",\n",
    "                \"available_for_vector_db\": true,\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"size\": {\n",
    "                \"name\": \"Size\",\n",
    "                \"description\": \"The size of the document\",\n",
    "                \"available_for_filter\": true,\n",
    "                \"available_for_vector_db\": true,\n",
    "                \"type\": \"int64\"\n",
    "            },\n",
    "            \"created_time\": {\n",
    "                \"name\": \"Created Time\",\n",
    "                \"description\": \"When the document was created in the project\",\n",
    "                \"available_for_filter\": true,\n",
    "                \"available_for_vector_db\": true,\n",
    "                \"type\": \"int64\"\n",
    "            },\n",
    "            \"modified_time\": {\n",
    "                \"name\": \"Modified Time\",\n",
    "                \"description\": \"When the document was last modified\",\n",
    "                \"available_for_filter\": true,\n",
    "                \"available_for_vector_db\": true,\n",
    "                \"type\": \"int64\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* ### `ingest_cpd_connections:` <small>Select the documents or folders you wish to ingest from Connections like \"Amazon S3\", \"Box\"</small>\n",
    "            \n",
    "\n",
    "* ### `ingest_document_set:` <small>Select the documents set or the base document set to ingest</small>\n",
    "   \n",
    "\n",
    "## Extract Operator\n",
    "This operator is designed to extract useful information from ingested data.\n",
    "* ### `extract_cpd:` <small>Extracts metadata or content from CPD assets.</small>\n",
    "\n",
    "## Quality Operator\n",
    "This operator help assess and improve the quality of data and documents.\n",
    "\n",
    "* ###  `lang_detect:`<small>Detects the language of a document.</small>\n",
    "\n",
    "* ### `doc_quality:` <small>Evaluates the quality of a document.</small>\n",
    "     \n",
    "* ###  `sql_filter:` <small>Applies SQL-based filtering to datasets.</small>\n",
    "\n",
    "* ###  `data_class_assignment:` <small>Assigns data to predefined classes.</small>\n",
    "   \n",
    "* ###  `term_assignment_operator:` <small>Assigns terms or tags to content.</small>\n",
    "     \n",
    "* ###  `pii_and_hap_extract_redact:` <small>Identifies and redacts sensitive information (PII/HAP).</small>\n",
    "         \n",
    "* ###  `redaction:` <small>Removes or masks sensitive content.</small>\n",
    "\n",
    "\n",
    "## Functional Operator\n",
    "These operators provide core processing capabilities.\n",
    "\n",
    "* ### `chunker:` <small>Breaks documents into smaller, manageable chunks.</small>\n",
    "\n",
    "* ### `embeddings:` <small>Converts text into vector representations for machine learning.</small>\n",
    "\n",
    "\n",
    "## VectorDB Operator\n",
    "These operators interact with vector databases for advanced search and retrieval.\n",
    "\n",
    "* ### `milvusdb_cp4d:` <small>Connects to Milvus vector database in CPD.</small>\n",
    "     \n",
    "* ### `document_set:` <small>Manages sets of documents in vector format</small>\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d2c36",
   "metadata": {},
   "source": [
    "## 4. Create Pipeline for execution\n",
    "To create a pipeline using UDPClient, you must define a list of operators in the order they should be executed. Each operator is a dictionary containing:\n",
    "\n",
    "* \"type\": The type of operation to perform.\n",
    "* \"parameters\" (optional): A dictionary of parameters required by that operator.You can get this parameters for the CAMS api for the particular asset. If you don't provide this if will just effect the UI view\n",
    "\n",
    "* ### Example\n",
    "```python\n",
    "        operators = [{\"type\": \"ingest_document_set\",\n",
    "                        \"parameters\": {\n",
    "                        \"document_set_id\":\"1b6d97c5-4585-4789-b075-873a1536d2e1\",\n",
    "                        \"input_assets\": {\n",
    "                            \"document_set_name\": \"prince_16june\",\n",
    "                            \"created_on\": \"2025-05-16T13:33:25Z\",\n",
    "                            \"document_set_id\":\"1b6d97c5-4585-4789-b075-873a1536d2e1\"\n",
    "                    }\n",
    "                        }},\n",
    "                    {\"type\": \"extract_cpd\"},\n",
    "                    {\"type\": \"chunker\"},\n",
    "                    {\"type\": \"embeddings\"},\n",
    "                    {\"type\": \"data_class_assignment\"}\n",
    "                    {\"type\": \"milvusdb_cp4d\"}]\n",
    "                    \n",
    "        #Get globalconfig\n",
    "        global_config= {\n",
    "            \"global_config\": {\n",
    "                \"data_local_config\": {\n",
    "                    \"output_folder\": \"./test/flows/output\"\n",
    "                },\n",
    "                \"data_storage_type\": \"local\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        flow_name = \"xyz\" # Name of your flow name\n",
    "        pipeline = {\n",
    "            \"flow_name\": flow_name,\n",
    "            \"project_id\": config.get('project_id'),\n",
    "            \"orchestrator\": \"python\",\n",
    "            \"flow\": operators,\n",
    "            \"global_config\": global_config\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccd72e",
   "metadata": {},
   "source": [
    "## 5. Get the Milvus Operator Feature Mapping Related Metadata\n",
    "\n",
    "#### Initial `milvusdb_cp4d` Type Operator  \n",
    "  ``` python\n",
    "      {\n",
    "        \"type\": \"milvusdb_cp4d\",\n",
    "        \"parameters\": {\n",
    "          \"connection_id\": \"<cp4d-connection-id>\",\n",
    "          \"collection_name\":\"<collection_name>\"\n",
    "        }\n",
    "      }\n",
    "  ```\n",
    "  if the `collection_name` not provided system will take `datasift` as default.\n",
    "\n",
    "By using  `milvus_feature_mapping_metadata = uc.get_milvus_feature_mapping_metadata(pipeline_details=pipeline)` you will get the milvus_feature_mapping metadata\n",
    "- `available_collections` ‚Äì Lists all collections available in the Milvus connection.\n",
    "- `collection_columns` ‚Äì Lists columns present in the specified collection.\n",
    "- `available_features` - Available features in the given pipeline that can be mapped to collection columns..\n",
    "- `milvus_feature_mappings` - Default feature mapping for the specified collection.\n",
    "* #### Example\n",
    "`available_collections = milvus_feature_mapping_metadata.get(\"available_collections\")`\n",
    "\n",
    "By using this you can update the milvus_embedding\n",
    "\n",
    "By using this you will be able to create and run the flow\n",
    "\n",
    "```python\n",
    "          from udp.flows import Flow\n",
    "          flow = Flow(uc)\n",
    "\n",
    "          try:\n",
    "            flow.create(flow_name, pipeline)\n",
    "            flow.run()\n",
    "            print(\"Status:\", flow.status())\n",
    "          \n",
    "          except Exception as e:\n",
    "              print(\"Error:\", e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
