{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSTRUCTURED DATA INTEGRATION\n",
    "\n",
    "The `ibm-udi` SDK for Python enables developers and data engineers to programmatically interact with the `unstructured data integration service`, IBM’s next-generation data integration platform built to support modern, hybrid-cloud data pipelines.\n",
    "\n",
    "With this SDK, users can automate and manage Flow lifecycles such as creating, configuring, starting, stopping, and monitoring Flows directly in code.\n",
    "\n",
    "## 0. INSTALL UDI PACKAGE\n",
    "\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update wheel file location below and install required packages\n",
    "%pip install ibm-udi\n",
    "%pip list | grep udi\n",
    "%pip install requests\n",
    "%pip install datetime\n",
    "%pip onstall pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create a client for Unstructured Data Integration \n",
    "\n",
    "\n",
    "### Authentication Requirements\n",
    "\n",
    "To create a `UDIClient`, **at least one** of the following authentication methods is required depending on the environment:\n",
    "\n",
    "To create a `UDIClient`, **at least one** of the following authentication methods is required depending on the environment:\n",
    "\n",
    "1. **For CPD -** \n",
    "    * Bearer Token\n",
    "    * Username and Password\n",
    "    * Username and API Key\n",
    "2. **For SaaS -** \n",
    "    * Bearer Token\n",
    "    * API Key\n",
    "3. **For AWS -**\n",
    "    * Bearen Token\n",
    "    * API Key\n",
    "\n",
    "### Base URL\n",
    "\n",
    "You must also provide the URL of your environment:\n",
    "\n",
    "- For SaaS you require an api path\n",
    "  \n",
    "  Example: `https://api.ca-tor.dai.cloud.ibm.com/`\n",
    "\n",
    "- For **Cloud Pak for Data (Watsonx)**:  \n",
    "  \n",
    "  Example → `https://<cp4d-cluster-hostname>`\n",
    "\n",
    "This will serve as the `base_url` to authenticate and manage your Unstructured data integration flows.\n",
    "\n",
    "\n",
    "### Create a New Project\n",
    "\n",
    "To work with Unstructured data integration flows, you need a project:\n",
    "\n",
    "1. Create a new project in your Watsonx or SaaS.\n",
    "2. Allocate the required **storage** for the project.\n",
    "3. Once created, obtain the `project_id` from the **project URL**.  \n",
    "   For example:  \n",
    "\n",
    "https://..../projects/<project_id>/...\n",
    "\n",
    "4. Import the documents you wish to ingest into the flow into your project and keep a note of their Asset ID(s) as it will be required for defining the flow operators for pipeline generation.\n",
    "\n",
    "Once these elements are in place, you're ready to instantiate your `UDIClient` and start building and managing Unstructured data integration flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udi import UDIClient\n",
    "from udi.utils import get_attributes, get_features\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure logging to display in notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env options: cpd | cloud-prod | mcsp-prod\n",
    "config = {\n",
    "    'base_url' : \"<ENTER-URL>\",\n",
    "    'token' : None,\n",
    "    'project_id' : \"<ENTER-PROJECT-ID>\",\n",
    "    'user_name' : None,\n",
    "    'password' : None,\n",
    "    'api_key' : None,\n",
    "    'env' : \"cpd\"\n",
    "}\n",
    "\n",
    "uc = UDIClient(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get List of Available Operators\n",
    "\n",
    "This step helps present a **structured view** of all available operators, grouped by functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_operators = uc.get_available_operators()\n",
    "print(json.dumps(ordered_operators, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get all Operator Metadata\n",
    "\n",
    "This is required to build the operator. From this all operator names and their attributes, features and required values can be retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Operator Metadata\n",
    "metadata = uc.get_metadata()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get Operator-Specific Details\n",
    "\n",
    "Fetch detailed metadata for a specific operator to view its attributes and features. This is essential for correctly building and validating flow components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Get Attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_attributes = get_attributes(metadata, \"extract_cpd\")\n",
    "print(json.dumps(operator_attributes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Get operator specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_features = get_features(metadata, \"extract_cpd\")\n",
    "print(json.dumps(operator_features, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Pipeline for Execution\n",
    "\n",
    "## 5.1 Create a sequence of operators based on operator metadata\n",
    "\n",
    "The `operators` list defines the full sequence of steps your UDI flow will follow — from data ingestion to vector storage.\n",
    "\n",
    "### How to Use It\n",
    "\n",
    "You will need to update two main parts in the `operators` list:\n",
    "\n",
    "- An **Asset List** is expected to be created by adding the asset_id(s) to the **data_assets** list which will be further used to retrieve the asset information. `(Optional - To Be Provided only for ingest_cpd_assets operator)`\n",
    "\n",
    "-  **Connection** details in the `milvusdb_cp4d` operator  \n",
    "\n",
    "### The other operators can be added or removed based on your requirements.\n",
    "\n",
    "Example: the given operator list does not include the `sql_filter` operator. This can be included if you wish to filter your documents based on some constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of input data assets\n",
    "data_assets = ['<ENTER-YOUR-ASSET-ID(s)>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_info = []\n",
    "\n",
    "for data in data_assets:\n",
    "    try:\n",
    "        asset = uc.get_data_asset(data)\n",
    "        # print(asset)\n",
    "        asset_info.append(asset)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"Final collected assets:\", asset_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = [\n",
    "    {\n",
    "        \"type\": \"ingest_cpd_assets\",\n",
    "        \"parameters\": {\n",
    "            \"input_assets\": asset_info\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"extract_cpd\",\n",
    "        \"parameters\": {\n",
    "            \"ocr_mode\": \"enabled\",           # Available Values: [enabled, disabled, forced]    \n",
    "            \"extract_entity\": True,           \n",
    "            \"custom_schema\": \"disabled\"        \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"lang_detect\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"chunker\",\n",
    "        \"parameters\": {\n",
    "            'chunk_type': 'watsonx',\n",
    "            'chunk_size': 4000,\n",
    "            'chunk_overlap': 200\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"embeddings\",\n",
    "        \"parameters\": {\n",
    "            \"embeddings_type\": \"watsonx\",\n",
    "            \"embeddings_model_id\": \"<ENTER-MODEL-ID>\"  # Example: ibm/slate-30m-english-rtrvr\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"milvusdb_cp4d\",\n",
    "        \"parameters\": {\n",
    "            \"connection_name\": \"<ENTER-CONNECTION-NAME>\",\n",
    "            \"connection_id\": \"<ENTER-CONNECTION-ID>\",\n",
    "            \"collection_name\": \"<ENTER-COLLECTION-NAME>\",   # Provide a new collection name\n",
    "            \"milvus_feature_mappings\": [\n",
    "                {\n",
    "                    \"feature_name\": \"name\",\n",
    "                    \"mapped_column_name\": \"document_name\"\n",
    "                },\n",
    "                {\n",
    "                    \"feature_name\": \"doc_id_hash\",\n",
    "                    \"mapped_column_name\": \"pk\"\n",
    "                },\n",
    "                {\n",
    "                    \"feature_name\": \"id\",\n",
    "                    \"mapped_column_name\": \"document_id\"\n",
    "                },\n",
    "                {\n",
    "                    \"feature_name\": \"embeddings\",\n",
    "                    \"mapped_column_name\": \"vector_embeddings\"\n",
    "                },\n",
    "                {\n",
    "                    \"feature_name\": \"sparse_embeddings\",\n",
    "                    \"mapped_column_name\": \"sparse_embeddings\"\n",
    "                },\n",
    "                {\n",
    "                    \"feature_name\": \"content\",\n",
    "                    \"mapped_column_name\": \"text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"document_set\",\n",
    "        \"parameters\": {\n",
    "            \"cp4d_connection_id\": \"<ENTER-YOUR-CONNECTION-ID>\",\n",
    "            \"catalog_name\": \"<ENTER-YOUR-CATALOG-NAME>\",\n",
    "            \"schema_name\": \"<ENTER-YOUR-SCHEMA-NAME>\",\n",
    "            \"connection_name\": \"<ENTER-YOUR-CONNECTION-NAME>\",\n",
    "            \"document_set_name\": \"<ENTER-YOUR-DOCUMENT-SET-NAME>\",\n",
    "            \"document_set_description\": \"The output document set\",\n",
    "            \"table_name\": \"<ENTER-YOUR-TABLE-NAME>\"\n",
    "        }\n",
    "    }     \n",
    "]\n",
    "\n",
    "# Replace the ingest above with below examples for different Ingest Types\n",
    "# {\n",
    "#     \"type\": \"ingest_cpd_connections\",\n",
    "#         \"parameters\": \n",
    "#         {\n",
    "#             \"connection_id\": \"409fe4ee-d80f-4f94-a9bc-6585660c6544\",\n",
    "#             \"paths\": [\n",
    "#                 \"/tm-wkc-storage-1/2_small_files\",\n",
    "#                  \"/tm-wkc-storage-1/8_pdf_small_files\",\n",
    "#                 \"/tm-wkc-storage-1/_PLT_Demo_/test_invoice_01.pdf\"\n",
    "#             ],\n",
    "#             \"include_filter\": \n",
    "#             [\n",
    "#                 \"pdf\", \"txt\",\"md\"\n",
    "#             ],\n",
    "#             \"max_file_size\": 100,\n",
    "#             \"max_files\": 100\n",
    "#         }\n",
    "# }\n",
    "\n",
    "# {\n",
    "#       \"type\": \"ingest_document_set\",\n",
    "#          \"parameters\": \n",
    "#           {\n",
    "#              \"document_set_id\":\"128e2fdf-e109-4bac-931f-2f8e9702ce4a\",\n",
    "#              \"input_assets\": \n",
    "#               {\n",
    "#                  \"document_set_name\": \"shivani_doc_set_11\",\n",
    "#                  \"created_on\": \"2025-05-16T13:33:25Z\",\n",
    "#                  \"document_set_id\":\"128e2fdf-e109-4bac-931f-2f8e9702ce4a\"\n",
    "#               }\n",
    "#           }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 CREATE PIPELINE\n",
    "\n",
    "Use the configured `operators` list to create the full pipeline dictionary, including the `flow_name`, `project_id`, `orchestrator`, and `global_config`. Set the `orchestrator` to `python` for small to medium flows, or `spark` if you're working with large documents.\n",
    "\n",
    "global_config is used to keep reusable pipeline settings (like storage paths and types) separate from the code. It injects the values into the pipeline so downstream operators know where to store outputs or which storage method to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = {\n",
    "        \"data_local_config\": {\n",
    "                \"output_folder\": \"./test/flows/output\"\n",
    "        },\n",
    "        \"data_storage_type\": \"local\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_name = f\"SDK_FLOW_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "pipeline = {\n",
    "    \"flow_name\": flow_name,\n",
    "    \"project_id\": config.get('project_id'),\n",
    "    \"orchestrator\": \"python\",\n",
    "    \"flow\": operators,\n",
    "    \"global_config\": global_config\n",
    "}\n",
    "print(\"pipeline : \",json.dumps(pipeline, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create and Run Flow\n",
    "\n",
    "\n",
    "Use the `Flow` class to create and run the pipeline by passing the `UDIClient` instance. Once executed, you can monitor its status and retrieve logs. Optional methods like `cancel()` and `delete()` are also available for managing the flow lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from udi.flows import Flow\n",
    "flow = Flow(uc)\n",
    "\n",
    "try:\n",
    "    flow.create(pipeline=pipeline)\n",
    "    flow.run()\n",
    "    print(\"Status:\", flow.status())\n",
    "    # flow.cancel()\n",
    "    # flow.delete()\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to get the execution logs of the flow\n",
    "print(\"Logs:\", flow.logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Poll Execution Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.poll_flow_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
